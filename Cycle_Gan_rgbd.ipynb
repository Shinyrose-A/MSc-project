{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SD7oicG2amg0"
      },
      "source": [
        "## packages and parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ed-YlRgiaU8-"
      },
      "outputs": [],
      "source": [
        "!pip install albumentations==0.4.6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b_y88Ireaql8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms\n",
        "import os\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import cv2\n",
        "import shutil\n",
        "from PIL import Image\n",
        "import sys\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "from torchvision.utils import save_image\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ej5rWjU4asqC"
      },
      "outputs": [],
      "source": [
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(DEVICE)\n",
        "BATCH_SIZE = 1\n",
        "LEARNING_RATE = 1e-5\n",
        "LAMBDA_IDENTITY = 0.0\n",
        "LAMBDA_CYCLE = 10\n",
        "NUM_WORKERS = 2\n",
        "NUM_EPOCHS = 20\n",
        "LOAD_MODEL = False\n",
        "SAVE_MODEL = True\n",
        "CHECKPOINT_GEN_S = \"/content/drive/MyDrive/Project/data/checkpoints/gens.pth.tar\"\n",
        "CHECKPOINT_GEN_R = \"/content/drive/MyDrive/Project/data/checkpoints/genr.pth.tar\"\n",
        "CHECKPOINT_CRITIC_S = \"/content/drive/MyDrive/Project/data/checkpoints/critics.pth.tar\"\n",
        "CHECKPOINT_CRITIC_R = \"/content/drive/MyDrive/Project/data/checkpoints/criticr.pth.tar\"\n",
        "\n",
        "TRANSFORMS_rgbd = A.Compose(\n",
        "    [\n",
        "        A.Resize(width=256, height=256),\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.Normalize(mean=[0.5, 0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5, 0.5], max_pixel_value=255),\n",
        "        ToTensorV2(),\n",
        "     ],\n",
        ")\n",
        "\n",
        "TRANSFORMS = A.Compose(\n",
        "    [\n",
        "        A.Resize(width=256, height=256),\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5], max_pixel_value=255),\n",
        "        ToTensorV2(),\n",
        "     ],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pGpE52NhbKy4"
      },
      "outputs": [],
      "source": [
        "def save_checkpoint(model, optimizer, PATH=\"my_checkpoint.pth.tar\"):\n",
        "    print(\"=> Saving checkpoint\")\n",
        "    checkpoint = {\n",
        "        \"state_dict\": model.state_dict(),\n",
        "        \"optimizer\": optimizer.state_dict(),\n",
        "    }\n",
        "    torch.save(checkpoint, PATH)\n",
        "\n",
        "\n",
        "def load_checkpoint(PATH, model, optimizer, lr):\n",
        "    print(\"=> Loading checkpoint\")\n",
        "    checkpoint = torch.load(PATH, map_location=DEVICE)\n",
        "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
        "    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
        "\n",
        "\n",
        "    optimizer.param_groups[0]['capturable'] = True\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group[\"lr\"] = lr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qUJujsXbO3h"
      },
      "source": [
        "## Discriminator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_TlH0OvLU9d"
      },
      "source": [
        "dense resnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UUuvCWhRbP8B"
      },
      "outputs": [],
      "source": [
        "class Block(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            # kernel size = 4, padding = 1\n",
        "            nn.Conv2d(in_channels, out_channels, 4,stride ,1 , bias=True, padding_mode=\"reflect\"),\n",
        "            nn.InstanceNorm2d(out_channels),\n",
        "            nn.LeakyReLU(0.2),\n",
        "        )\n",
        "\n",
        "    def forward(self,x):\n",
        "        return self.conv(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YFCVthqCbSFh"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, in_channels = 3, features = [64, 128, 256, 512]):\n",
        "        super().__init__()\n",
        "        self.initial = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, features[0], kernel_size=4, stride=2, padding=1, padding_mode=\"reflect\"),\n",
        "            nn.LeakyReLU(0.2),\n",
        "        )\n",
        "\n",
        "        layers = []\n",
        "        in_channels = features[0]\n",
        "        for feature in features[1:]:\n",
        "            # stride = 1 for last one and 2 for first 3\n",
        "            layers.append(Block(in_channels, feature, stride = 1 if feature == features[-1] else 2))\n",
        "            in_channels = feature\n",
        "        # the out_channels is 1, since output 0 or 1 to indicate true or fake\n",
        "        layers.append(nn.Conv2d(in_channels, 1, kernel_size=4, stride=1, padding=1, padding_mode=\"reflect\"))\n",
        "        self.model = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.initial(x)\n",
        "        return torch.sigmoid(self.model(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmAlIU2abU_9"
      },
      "source": [
        "## Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WHKNnawCba5_"
      },
      "outputs": [],
      "source": [
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, down=True, use_act=True, **kwargs):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, padding_mode=\"reflect\", **kwargs) \n",
        "            if down\n",
        "            else nn.ConvTranspose2d(in_channels, out_channels, **kwargs),\n",
        "            nn.InstanceNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True) if use_act else nn.Identity()\n",
        "\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super().__init__()\n",
        "        self.block = nn.Sequential(\n",
        "            ConvBlock(channels, channels, kernel_size=3, padding=1),\n",
        "            ConvBlock(channels, channels, use_act=False, kernel_size=3, padding=1),\n",
        "        )\n",
        "\n",
        "    def forward(self,x):\n",
        "        return x + self.block(x)"
      ],
      "metadata": {
        "id": "gIQ_rnINTQOB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AfATmHuSbgZo"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    # num_residuals can be 6 or 9\n",
        "    def __init__(self, in_channels, out_channels, num_features = 64, num_residuals=9):\n",
        "        super().__init__()\n",
        "        self.initial = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, num_features, kernel_size=7, stride=1, padding=3, padding_mode=\"reflect\"),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "        self.down_blocks = nn.ModuleList(\n",
        "            [\n",
        "                ConvBlock(num_features, num_features*2, kernel_size=3, stride=2, padding=1),\n",
        "                ConvBlock(num_features*2, num_features*4, kernel_size=3, stride=2, padding=1),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        self.residual_blocks = nn.Sequential(\n",
        "            *[ResidualBlock(num_features*4) for _ in range(num_residuals)]\n",
        "        )\n",
        "\n",
        "        self.up_blocks = nn.ModuleList(\n",
        "            [\n",
        "                ConvBlock(num_features*4, num_features*2, down=False, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "                ConvBlock(num_features*2, num_features, down=False, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        self.last = nn.Conv2d(num_features, out_channels, kernel_size=7, stride=1, padding=3, padding_mode=\"reflect\")\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.initial(x)\n",
        "        for layer in self.down_blocks:\n",
        "            x = layer(x)\n",
        "        x = self.residual_blocks(x)\n",
        "        for layer in self.up_blocks:\n",
        "            x = layer(x)\n",
        "        return torch.tanh(self.last(x))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test():\n",
        "    in_channels = 4\n",
        "    out_channels = 3\n",
        "    img_size = 256\n",
        "    x = torch.randn((2, in_channels, img_size, img_size))\n",
        "    gen = Generator(in_channels, out_channels)\n",
        "    #print(gen)\n",
        "    print(gen(x).shape)\n",
        "\n",
        "test()"
      ],
      "metadata": {
        "id": "Bu9mba0GJK6j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmMq0L7fbhiH"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TrXtLU-8bkqM"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yoENS48boTb"
      },
      "source": [
        "### Generate rgbd image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gYv5shGMbvv0"
      },
      "outputs": [],
      "source": [
        "def gen_rgbd(rgb_path, depth_path):\n",
        "    rgb_path_list = os.listdir(rgb_path)\n",
        "    rgb_path_list.sort()\n",
        "    depth_path_list = os.listdir(depth_path)\n",
        "    depth_path_list.sort()\n",
        "\n",
        "    number=1\n",
        "    for i, name in enumerate(rgb_path_list):\n",
        "        rgb_path_single = rgb_path+'/'+rgb_path_list[i]\n",
        "        depth_path_single = depth_path+'/'+depth_path_list[i]\n",
        "        #print(rgb_path_single)\n",
        "        #print(depth_path_single)\n",
        "        \n",
        "        # actually rgba(red, green, blue, alpha), so get first three channels\n",
        "        rgb = cv2.imread(rgb_path_single, cv2.IMREAD_UNCHANGED)\n",
        "        depth = cv2.imread(depth_path_single, cv2.IMREAD_UNCHANGED)\n",
        "        \n",
        "        rgb_array = np.array(rgb)\n",
        "        depth_array = np.array(depth)\n",
        "        #print(rgb_array.shape)\n",
        "        #print(depth_array.shape)\n",
        "\n",
        "        rgbd = np.zeros((256,256,4),dtype=np.uint8)\n",
        "        rgbd[:, :, 0] = rgb[:, :, 0]\n",
        "        rgbd[:, :, 1] = rgb[:, :, 1]\n",
        "        rgbd[:, :, 2] = rgb[:, :, 2]\n",
        "        rgbd[:, :, 3] = depth\n",
        "\n",
        "        #print(rgbd)\n",
        "\n",
        "        img_name = str(number)+'.png'\n",
        "        number+=1\n",
        "        save_path = \"/content/drive/MyDrive/Project/data/rgbd\"\n",
        "        if os.path.exists(save_path):\n",
        "            save_img = save_path + '/' +img_name\n",
        "            cv2.imwrite(save_img, rgbd)\n",
        "        else:\n",
        "            os.mkdir(save_path)\n",
        "            save_img = save_path + '/' +img_name\n",
        "            cv2.imwrite(save_img, rgbd)\n",
        "        \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def getFileNames(rootDir):\n",
        "    fileNames = []\n",
        "    for dirName, subDirList, fileList in os.walk(rootDir):\n",
        "        for fname in fileList:\n",
        "            if os.path.splitext(fname)[1] == '.png':\n",
        "                fileNames.append(dirName+'/'+fname)\n",
        "    return fileNames"
      ],
      "metadata": {
        "id": "VFcTAaj9noWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBYLhvZ_fc82"
      },
      "source": [
        "### Load images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BKP83t8yfdau"
      },
      "outputs": [],
      "source": [
        "class gen_dataset(Dataset):\n",
        "    def __init__(self, root_rgbd, root_real, transform=None, transform_rgbd=None):\n",
        "        self.root_rgbd = root_rgbd\n",
        "        self.root_real = root_real\n",
        "        self.transform = transform\n",
        "        self.transform_rgbd = transform_rgbd\n",
        "\n",
        "        # to make os.listdir not shuffle\n",
        "        #root_syntheic = os.getcwd()\n",
        "\n",
        "        self.rgbd_images = os.listdir(root_rgbd)\n",
        "        self.real_images = os.listdir(root_real)\n",
        "\n",
        "\n",
        "        self.length_dataset = max(len(self.rgbd_images), len(self.real_images))\n",
        "        self.rgbd_length = len(self.rgbd_images)\n",
        "        self.real_length = len(self.real_images)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length_dataset\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        rgbd_img = self.rgbd_images[index % self.rgbd_length]\n",
        "        real_img = self.real_images[index % self.real_length]\n",
        "\n",
        "        rgbd_path = os.path.join(self.root_rgbd, rgbd_img)\n",
        "        real_path = os.path.join(self.root_real, real_img)\n",
        "\n",
        "        rgbd_img = np.array(Image.open(rgbd_path))\n",
        "        real_img = np.array(Image.open(real_path).convert(\"RGB\"))\n",
        "        #real_img = real_img.permute(2,0,1)\n",
        "\n",
        "        if self.transform:\n",
        "\n",
        "            real_img = self.transform(image=real_img)[\"image\"]\n",
        "        if self.transform_rgbd:\n",
        "            rgbd_img = self.transform_rgbd(image=rgbd_img)[\"image\"]\n",
        "\n",
        "        \n",
        "        return rgbd_img, real_img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvcrGciti-by"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFRt4b5li-8P"
      },
      "outputs": [],
      "source": [
        "def train_fn(disc_S, disc_R, gen_S, gen_R, loader, opt_disc, opt_gen, l1, mse, d_scaler, g_scaler, epoch):\n",
        "    D_loss_all = 0\n",
        "    G_loss_all = 0\n",
        "    loop = tqdm(loader, leave=True)\n",
        "\n",
        "    for idx, (rgbd_img, real_img) in enumerate(loop):\n",
        "        #syntheic_img = syntheic_img.permute(0,3,1,2)\n",
        "        #depth_img = depth_img.permute(0,3,1,2)\n",
        "        #real_img = real_img.permute(0,3,1,2)\n",
        "\n",
        "        #input_img = syntheic_img\n",
        "        input_img = rgbd_img\n",
        "        #real_img = torch.cat([real_img, depth_img],1)\n",
        "        input_img = input_img.float()\n",
        "        real_img = real_img.float()\n",
        "        \n",
        "        input_img = input_img.to(DEVICE)\n",
        "        real_img = real_img.to(DEVICE)\n",
        "\n",
        "        \n",
        "        # Train Discriminators\n",
        "        with torch.cuda.amp.autocast():\n",
        "            # Disc R\n",
        "            fake_R = gen_R(input_img)\n",
        "            D_R_real = disc_R(real_img)\n",
        "            D_R_fake = disc_R(fake_R.detach())\n",
        "\n",
        "            #R_reals += D_R_real.mean().item()\n",
        "            #R_fakes += D_R_fake.mean().item()\n",
        "\n",
        "            D_R_real_loss = mse(D_R_real, torch.ones_like(D_R_real))\n",
        "            D_R_fake_loss = mse(D_R_fake, torch.zeros_like(D_R_fake))\n",
        "            D_R_loss = D_R_real_loss + D_R_fake_loss\n",
        "\n",
        "            # Disc S\n",
        "            fake_S = gen_S(real_img)\n",
        "            D_S_real = disc_S(input_img)\n",
        "            D_S_fake = disc_S(fake_S.detach())\n",
        "\n",
        "            D_S_real_loss = mse(D_S_real, torch.ones_like(D_S_real))\n",
        "            D_S_fake_loss = mse(D_S_fake, torch.zeros_like(D_S_fake))\n",
        "            D_S_loss = D_S_real_loss + D_S_fake_loss\n",
        "\n",
        "            # put it togethor\n",
        "            D_loss = (D_R_loss + D_S_loss)/2\n",
        "            D_loss_all += D_loss\n",
        "            #print('\\n'+str(D_loss.item()))\n",
        "\n",
        "        opt_disc.zero_grad()\n",
        "        d_scaler.scale(D_loss).backward()\n",
        "        d_scaler.step(opt_disc)\n",
        "        d_scaler.update()\n",
        "\n",
        "        # Train Generators\n",
        "        with torch.cuda.amp.autocast():\n",
        "            # adversarial loss for both generators\n",
        "            D_R_fake = disc_R(fake_R)\n",
        "            D_S_fake = disc_S(fake_S)\n",
        "            loss_G_R = mse(D_R_fake, torch.ones_like(D_R_fake))\n",
        "            loss_G_S = mse(D_S_fake, torch.ones_like(D_S_fake))\n",
        "\n",
        "            # cycle loss\n",
        "            cycle_S = gen_S(fake_R)\n",
        "            cycle_R = gen_R(fake_S)\n",
        "            cycle_S_loss = l1(input_img, cycle_S)\n",
        "            cycle_R_loss = l1(real_img, cycle_R)\n",
        "\n",
        "            # identity loss (set lambda_identity=0)\n",
        "            identity_S = 0 #gen_S(input_img)\n",
        "            identity_R = 0 #gen_R(real_img)\n",
        "            identity_S_loss = 0 #l1(input_img, identity_S)\n",
        "            identity_R_loss = 0 #l1(real_img, identity_R)\n",
        "\n",
        "            # add all togethor\n",
        "            G_loss = (\n",
        "                loss_G_S\n",
        "                + loss_G_R\n",
        "                + cycle_S_loss * LAMBDA_CYCLE\n",
        "                + cycle_R_loss * LAMBDA_CYCLE\n",
        "                + identity_R_loss * LAMBDA_IDENTITY\n",
        "                + identity_S_loss * LAMBDA_IDENTITY\n",
        "            )\n",
        "            \n",
        "            G_loss_all += G_loss\n",
        "            #print('\\n'+str(G_loss.item()))\n",
        "\n",
        "        opt_gen.zero_grad()\n",
        "        g_scaler.scale(G_loss).backward()\n",
        "        g_scaler.step(opt_gen)\n",
        "        g_scaler.update()\n",
        "\n",
        "        #fake_R = fake_R.squeeze()/2*255+.5*255\n",
        "        \n",
        "\n",
        "        if idx % 1000 == 0:\n",
        "            save_image(fake_R[0]*0.5+0.5, f\"/content/drive/MyDrive/Project/data/saved_images_rgbd/real_{epoch}_{idx}.png\")\n",
        "            #print(fake_R[0])\n",
        "            #save_image(fake_S[0], f\"/content/drive/MyDrive/Project/data/saved_images/syntheic_{idx}.png\")\n",
        "\n",
        "        #loop.set_postfix(R_real=R_reals/(idx+1), R_fake=R_fakes/(idx+1))\n",
        "        #loop.set_postfix(D_loss = D_loss.item(), G_loss = G_loss.item())\n",
        "\n",
        "        D_loss_avg = D_loss_all/(idx+1)\n",
        "        G_loss_avg = G_loss_all/(idx+1)\n",
        "\n",
        "        loop.set_postfix(D_loss = D_loss_avg.item(), G_loss = G_loss_avg.item(), epoch = epoch)\n",
        "\n",
        "    return D_loss_avg.item(), G_loss_avg.item() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "diAcLQBbjC9b"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "    disc_S = Discriminator(in_channels=4).to(DEVICE)\n",
        "    disc_R = Discriminator(in_channels=3).to(DEVICE)\n",
        "    gen_S = Generator(in_channels=3, out_channels=4, num_residuals=9).to(DEVICE)\n",
        "    gen_R = Generator(in_channels=4, out_channels=3, num_residuals=9).to(DEVICE)\n",
        "\n",
        "    opt_disc = optim.Adam(\n",
        "        list(disc_S.parameters())+list(disc_R.parameters()),\n",
        "        lr = LEARNING_RATE,\n",
        "        betas = (0.5, 0.999)\n",
        "    )\n",
        "    opt_gen = optim.Adam(\n",
        "        list(gen_S.parameters())+list(gen_R.parameters()),\n",
        "        lr = LEARNING_RATE,\n",
        "        betas = (0.5, 0.999)\n",
        "    )\n",
        "\n",
        "    #loss\n",
        "    L1 = nn.L1Loss()\n",
        "    mse = nn.MSELoss()\n",
        "\n",
        "    if LOAD_MODEL:\n",
        "        load_checkpoint(\n",
        "            CHECKPOINT_GEN_S, gen_S, opt_gen, LEARNING_RATE,\n",
        "        )\n",
        "\n",
        "        load_checkpoint(\n",
        "            CHECKPOINT_GEN_R, gen_R, opt_gen, LEARNING_RATE,\n",
        "        )\n",
        "\n",
        "        load_checkpoint(\n",
        "            CHECKPOINT_CRITIC_S, disc_S, opt_disc, LEARNING_RATE,\n",
        "        )\n",
        "\n",
        "        load_checkpoint(\n",
        "            CHECKPOINT_CRITIC_R, disc_R, opt_disc, LEARNING_RATE,\n",
        "        )\n",
        "\n",
        "\n",
        "    Dataset = gen_dataset(root_rgbd = \"/content/drive/MyDrive/Project/data/rgbd\",\n",
        "                      root_real = \"/content/drive/MyDrive/Project/data/real_resized_specfic\",\n",
        "                      transform=TRANSFORMS,\n",
        "                      transform_rgbd=TRANSFORMS_rgbd)\n",
        "\n",
        "    loader = DataLoader(Dataset, batch_size = BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory = True)\n",
        "\n",
        "    g_scaler = torch.cuda.amp.GradScaler()\n",
        "    d_scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "    D_loss_list = []\n",
        "    G_loss_list = []\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        D_loss_avg, G_loss_avg = train_fn(disc_S, disc_R, gen_S, gen_R, loader, opt_disc, opt_gen, L1, mse, d_scaler, g_scaler, epoch)\n",
        "\n",
        "        D_loss_list.append(D_loss_avg)\n",
        "        G_loss_list.append(G_loss_avg)\n",
        "        \n",
        "        if SAVE_MODEL:\n",
        "            save_checkpoint(gen_S, opt_gen, PATH=CHECKPOINT_GEN_S)\n",
        "            save_checkpoint(gen_R, opt_gen, PATH=CHECKPOINT_GEN_R)\n",
        "            save_checkpoint(disc_S, opt_disc, PATH=CHECKPOINT_CRITIC_S)\n",
        "            save_checkpoint(disc_R, opt_disc, PATH=CHECKPOINT_CRITIC_R)\n",
        "\n",
        "    print(D_loss_list)\n",
        "    print(G_loss_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pTO7KLLdjS5v"
      },
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test"
      ],
      "metadata": {
        "id": "0ywNJPMOdxN_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class gen_dataset_test(Dataset):\n",
        "    def __init__(self, root_rgbd, root_real, root_compare_rgb, root_compare_depth, transform=None, transform_rgbd=None):\n",
        "        self.root_rgbd = root_rgbd\n",
        "        self.root_real = root_real\n",
        "        self.root_compare_rgb = root_compare_rgb\n",
        "        self.root_compare_depth = root_compare_depth\n",
        "        self.transform = transform\n",
        "        self.transform_rgbd = transform_rgbd\n",
        "\n",
        "        # to make os.listdir not shuffle\n",
        "        #root_syntheic = os.getcwd()\n",
        "\n",
        "        self.rgbd_images = os.listdir(root_rgbd)\n",
        "        self.real_images = os.listdir(root_real)\n",
        "\n",
        "\n",
        "        self.length_dataset = max(len(self.rgbd_images), len(self.real_images))\n",
        "        self.rgbd_length = len(self.rgbd_images)\n",
        "        self.real_length = len(self.real_images)\n",
        "\n",
        "        #self.rgbd_images.sort()\n",
        "        self.compare_rgb_images = os.listdir(root_compare_rgb)\n",
        "        self.compare_rgb_images.sort()\n",
        "        self.compare_depth_images = os.listdir(root_compare_depth)\n",
        "        self.compare_depth_images.sort()        \n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length_dataset\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        rgbd_img = self.rgbd_images[index % self.rgbd_length]\n",
        "        real_img = self.real_images[index % self.real_length]\n",
        "        compare_rgb_img = self.compare_rgb_images[index % self.real_length]\n",
        "        compare_depth_img = self.compare_depth_images[index % self.real_length]\n",
        "\n",
        "        rgbd_path = os.path.join(self.root_rgbd, rgbd_img)\n",
        "        real_path = os.path.join(self.root_real, real_img)\n",
        "        compare_rgb_path = os.path.join(self.root_compare_rgb, compare_rgb_img)\n",
        "        compare_depth_path = os.path.join(self.root_compare_depth, compare_depth_img)\n",
        "\n",
        "        rgbd_img = np.array(Image.open(rgbd_path))\n",
        "        real_img = np.array(Image.open(real_path).convert(\"RGB\"))\n",
        "\n",
        "\n",
        "        if self.transform:\n",
        "            real_img = self.transform(image=real_img)[\"image\"]\n",
        "        if self.transform_rgbd:\n",
        "            rgbd_img = self.transform_rgbd(image=rgbd_img)[\"image\"]\n",
        "\n",
        "        \n",
        "        return rgbd_img, real_img, compare_rgb_path, compare_depth_path, rgbd_path"
      ],
      "metadata": {
        "id": "QzHF8wXmdwC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_fn(disc_S, disc_R, gen_S, gen_R, loader, opt_disc, opt_gen, epoch):\n",
        "    D_loss_all = 0\n",
        "    G_loss_all = 0\n",
        "    loop = tqdm(loader, leave=True)\n",
        "\n",
        "    for idx, (rgbd_img, real_img, compare_rgb_path, compare_depth_path, rgbd_path) in enumerate(loop):\n",
        "        input_img = rgbd_img\n",
        "\n",
        "        input_img = input_img.float()\n",
        "        real_img = real_img.float()\n",
        "        \n",
        "        input_img = input_img.to(DEVICE)\n",
        "        real_img = real_img.to(DEVICE)\n",
        "\n",
        "        fake_R = gen_R(input_img)\n",
        "\n",
        "        if idx % 2 == 0:\n",
        "            save_image(fake_R[0]*0.5+0.5, f\"/content/drive/MyDrive/Project/data/result_rgbd_original/output/output_{epoch}_{idx}.png\")\n",
        "\n",
        "            rgb_img = cv2.imread((compare_rgb_path[0]), cv2.IMREAD_COLOR)\n",
        "            depth_img = cv2.imread((compare_depth_path[0]), cv2.IMREAD_GRAYSCALE)\n",
        "            cv2.imwrite(f\"/content/drive/MyDrive/Project/data/result_rgbd_original/synthetic/input_rgb_{epoch}_{idx}.png\", rgb_img)\n",
        "            cv2.imwrite(f\"/content/drive/MyDrive/Project/data/result_rgbd_original/depth/input_depth_{epoch}_{idx}.png\", depth_img) \n",
        "\n",
        "            #print(fake_R[0])\n",
        "            #out_image = input_img[:,0:3,:,:]\n",
        "            #save_image(out_image[0], f\"/content/drive/MyDrive/Project/data/saved_images_rgbd_pix/input_{epoch}_{idx}.png\")\n",
        "\n",
        "        #loop.set_postfix(R_real=R_reals/(idx+1), R_fake=R_fakes/(idx+1))\n",
        "        #loop.set_postfix(D_loss = D_loss.item(), G_loss = G_loss.item())\n",
        "\n",
        "        D_loss_avg = D_loss_all/(idx+1)\n",
        "        G_loss_avg = G_loss_all/(idx+1)\n",
        "\n",
        "        loop.set_postfix(epoch = epoch)\n",
        " "
      ],
      "metadata": {
        "id": "PCzdncCKeIgp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    disc_S = Discriminator(in_channels=4).to(DEVICE)\n",
        "    disc_R = Discriminator(in_channels=3).to(DEVICE)\n",
        "    gen_S = Generator(in_channels=3, out_channels=4, num_residuals=9).to(DEVICE)\n",
        "    gen_R = Generator(in_channels=4, out_channels=3, num_residuals=9).to(DEVICE)\n",
        "\n",
        "    opt_disc = optim.Adam(\n",
        "        list(disc_S.parameters())+list(disc_R.parameters()),\n",
        "        lr = LEARNING_RATE,\n",
        "        betas = (0.5, 0.999)\n",
        "    )\n",
        "    opt_gen = optim.Adam(\n",
        "        list(gen_S.parameters())+list(gen_R.parameters()),\n",
        "        lr = LEARNING_RATE,\n",
        "        betas = (0.5, 0.999)\n",
        "    )\n",
        "\n",
        "    #loss\n",
        "    L1 = nn.L1Loss()\n",
        "    mse = nn.MSELoss()\n",
        "\n",
        "    LOAD_MODEL = True\n",
        "\n",
        "    if LOAD_MODEL:\n",
        "        load_checkpoint(\n",
        "            CHECKPOINT_GEN_S, gen_S, opt_gen, LEARNING_RATE,\n",
        "        )\n",
        "\n",
        "        load_checkpoint(\n",
        "            CHECKPOINT_GEN_R, gen_R, opt_gen, LEARNING_RATE,\n",
        "        )\n",
        "\n",
        "        load_checkpoint(\n",
        "            CHECKPOINT_CRITIC_S, disc_S, opt_disc, LEARNING_RATE,\n",
        "        )\n",
        "\n",
        "        load_checkpoint(\n",
        "            CHECKPOINT_CRITIC_R, disc_R, opt_disc, LEARNING_RATE,\n",
        "        )\n",
        "\n",
        "\n",
        "    Dataset = gen_dataset_test(root_rgbd = \"/content/drive/MyDrive/Project/data/rgbd_order\",\n",
        "                      root_real = \"/content/drive/MyDrive/Project/data/real_resized\",\n",
        "                      root_compare_rgb = \"/content/drive/MyDrive/Project/data/synthetic\",\n",
        "                      root_compare_depth = \"/content/drive/MyDrive/Project/data/depth map\",\n",
        "                      transform=TRANSFORMS,\n",
        "                      transform_rgbd=TRANSFORMS_rgbd)\n",
        "\n",
        "    loader = DataLoader(Dataset, batch_size = BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory = True)\n",
        "\n",
        "\n",
        "    D_loss_list = []\n",
        "    G_loss_list = []\n",
        "\n",
        "    NUM_EPOCHS = 1\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        test_fn(disc_S, disc_R, gen_S, gen_R, loader, opt_disc, opt_gen, epoch)\n"
      ],
      "metadata": {
        "id": "VCVuMt0zfmja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "cRgzm3OnfqY9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Metrics"
      ],
      "metadata": {
        "id": "BGdrFr7VgXnD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pytorch-fid==0.1.1"
      ],
      "metadata": {
        "id": "gmfrLLlDgYF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pytorch_fid.fid_score"
      ],
      "metadata": {
        "id": "Py4Nf4MngaaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pytorch_fid.fid_score.calculate_fid_given_paths(['/content/drive/MyDrive/Project/data/real_resized_specfic', '/content/drive/MyDrive/Project/data/result_rgbd_original/output'], 1, 'cude', 2048)"
      ],
      "metadata": {
        "id": "mKzAEkQbgb-s"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "2qUJujsXbO3h",
        "zmAlIU2abU_9",
        "9yoENS48boTb"
      ],
      "provenance": [],
      "mount_file_id": "1ZQGjYqmzw2KaTkH1wk-0Fs9dcpN-0vN6",
      "authorship_tag": "ABX9TyPQux+PXyqDC0d0KSlf3IFj"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}