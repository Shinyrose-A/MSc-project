{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SD7oicG2amg0"
      },
      "source": [
        "## packages and parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ed-YlRgiaU8-"
      },
      "outputs": [],
      "source": [
        "!pip install albumentations==0.4.6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b_y88Ireaql8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms\n",
        "import os\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import cv2\n",
        "import shutil\n",
        "from PIL import Image\n",
        "import sys\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "from torchvision.utils import save_image\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ej5rWjU4asqC"
      },
      "outputs": [],
      "source": [
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(DEVICE)\n",
        "BATCH_SIZE = 1\n",
        "LEARNING_RATE = (1e-6)\n",
        "LAMBDA_IDENTITY = 0.0\n",
        "LAMBDA_CYCLE = 10\n",
        "NUM_WORKERS = 2\n",
        "NUM_EPOCHS = 20\n",
        "LOAD_MODEL = False\n",
        "SAVE_MODEL = True\n",
        "CHECKPOINT_GEN_S = \"/content/drive/MyDrive/Project/data/checkpoints/gens_pix_rgb_PATCH70_noskip.pth.tar\"\n",
        "CHECKPOINT_GEN_R = \"/content/drive/MyDrive/Project/data/checkpoints/genr_pix_rgb_PATCH70_noskip.pth.tar\"\n",
        "CHECKPOINT_CRITIC_S = \"/content/drive/MyDrive/Project/data/checkpoints/critics_pix_rgb_PATCH70_noskip.pth.tar\"\n",
        "CHECKPOINT_CRITIC_R = \"/content/drive/MyDrive/Project/data/checkpoints/criticr_pix_rgb_PATCH70_noskip.pth.tar\"\n",
        "\n",
        "TRANSFORMS_rgbd = A.Compose(\n",
        "    [\n",
        "        A.Resize(width=256, height=256),\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.Normalize(mean=[0.5, 0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5, 0.5], max_pixel_value=255),\n",
        "        ToTensorV2(),\n",
        "     ],\n",
        ")\n",
        "\n",
        "TRANSFORMS = A.Compose(\n",
        "    [\n",
        "        A.Resize(width=256, height=256),\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5], max_pixel_value=255),\n",
        "        ToTensorV2(),\n",
        "     ],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pGpE52NhbKy4"
      },
      "outputs": [],
      "source": [
        "def save_checkpoint(model, optimizer, PATH=\"my_checkpoint.pth.tar\"):\n",
        "    print(\"=> Saving checkpoint\")\n",
        "    checkpoint = {\n",
        "        \"state_dict\": model.state_dict(),\n",
        "        \"optimizer\": optimizer.state_dict(),\n",
        "    }\n",
        "    torch.save(checkpoint, PATH)\n",
        "\n",
        "\n",
        "def load_checkpoint(PATH, model, optimizer, lr):\n",
        "    print(\"=> Loading checkpoint\")\n",
        "    checkpoint = torch.load(PATH, map_location=DEVICE)\n",
        "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
        "    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
        "\n",
        "    optimizer.param_groups[0]['capturable'] = True\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group[\"lr\"] = lr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qUJujsXbO3h"
      },
      "source": [
        "## Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UUuvCWhRbP8B"
      },
      "outputs": [],
      "source": [
        "class CNNBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            # kernel size = 4, padding = 1\n",
        "            nn.Conv2d(in_channels, out_channels, 4,stride ,1 , bias=True, padding_mode=\"reflect\"),\n",
        "            nn.InstanceNorm2d(out_channels),\n",
        "            nn.LeakyReLU(0.2),\n",
        "        )\n",
        "\n",
        "    def forward(self,x):\n",
        "        return self.conv(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YFCVthqCbSFh"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, in_channels = 3, features = [64, 128, 256, 512]):\n",
        "        super().__init__()\n",
        "        self.initial = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, features[0], kernel_size=4, stride=2, padding=1, padding_mode=\"reflect\"),\n",
        "            nn.LeakyReLU(0.2),\n",
        "        )\n",
        "\n",
        "        layers = []\n",
        "        in_channels = features[0]\n",
        "        for feature in features[1:]:\n",
        "            # stride = 1 for last one and 2 for first 3\n",
        "            layers.append(CNNBlock(in_channels, feature, stride = 1 if feature == features[-1] else 2))\n",
        "            in_channels = feature\n",
        "        # the out_channels is 1, since output 0 or 1 to indicate true or fake\n",
        "        layers.append(nn.Conv2d(in_channels, 1, kernel_size=4, stride=1, padding=1, padding_mode=\"reflect\"))\n",
        "        self.model = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.initial(x)\n",
        "        return torch.sigmoid(self.model(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GhAIrf0iVOrf"
      },
      "outputs": [],
      "source": [
        "def test():\n",
        "    x = torch.randn((5,3,256,256))\n",
        "    model = Discriminator(in_channels=3)\n",
        "    preds = model(x)\n",
        "    print(preds.shape)\n",
        "\n",
        "test()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmAlIU2abU_9"
      },
      "source": [
        "## U-net Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P-NQ5OZUT4CC"
      },
      "outputs": [],
      "source": [
        "class Block(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, down=True, act=\"relu\", use_dropout=False):\n",
        "        super(Block, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, 4, 2, 1, bias=False, padding_mode=\"reflect\")\n",
        "            if down\n",
        "            else nn.ConvTranspose2d(in_channels, out_channels, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace = True) if act == \"relu\" else nn.LeakyReLU(0.2),\n",
        "        )\n",
        "\n",
        "        self.use_dropout = use_dropout\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.down = down\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return self.dropout(x) if self.use_dropout else x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-nS5Iq9ZT6kB"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, in_channels=3, out_channels=3, features=64):\n",
        "        super().__init__()\n",
        "        self.initial_down = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, features, 4, 2, 1, padding_mode=\"reflect\"),\n",
        "            nn.LeakyReLU(0.2),\n",
        "        )\n",
        "        self.down1 = Block(features, features * 2, down=True, act=\"leaky\", use_dropout=False)\n",
        "        self.down2 = Block(\n",
        "            features * 2, features * 4, down=True, act=\"leaky\", use_dropout=False\n",
        "        )\n",
        "        self.down3 = Block(\n",
        "            features * 4, features * 8, down=True, act=\"leaky\", use_dropout=False\n",
        "        )\n",
        "        self.down4 = Block(\n",
        "            features * 8, features * 8, down=True, act=\"leaky\", use_dropout=False\n",
        "        )\n",
        "        self.down5 = Block(\n",
        "            features * 8, features * 8, down=True, act=\"leaky\", use_dropout=False\n",
        "        )\n",
        "        self.down6 = Block(\n",
        "            features * 8, features * 8, down=True, act=\"leaky\", use_dropout=False\n",
        "        )\n",
        "        self.bottleneck = nn.Sequential(\n",
        "            nn.Conv2d(features * 8, features * 8, 4, 2, 1), nn.ReLU(inplace = True)\n",
        "        )\n",
        "\n",
        "        self.up1 = Block(features * 8, features * 8, down=False, act=\"relu\", use_dropout=False)\n",
        "        self.up2 = Block(\n",
        "            features * 8 * 2, features * 8, down=False, act=\"relu\", use_dropout=False\n",
        "        )\n",
        "        self.up3 = Block(\n",
        "            features * 8 * 2, features * 8, down=False, act=\"relu\", use_dropout=False\n",
        "        )\n",
        "        self.up4 = Block(\n",
        "            features * 8 * 2, features * 8, down=False, act=\"relu\", use_dropout=False\n",
        "        )\n",
        "        self.up5 = Block(\n",
        "            features * 8 * 2, features * 4, down=False, act=\"relu\", use_dropout=False\n",
        "        )\n",
        "        self.up6 = Block(\n",
        "            features * 4 * 2, features * 2, down=False, act=\"relu\", use_dropout=False\n",
        "        )\n",
        "        self.up7 = Block(features * 2 * 2, features, down=False, act=\"relu\", use_dropout=False)\n",
        "        self.final_up = nn.Sequential(\n",
        "            nn.ConvTranspose2d(features * 2, out_channels, kernel_size=4, stride=2, padding=1),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        d1 = self.initial_down(x)\n",
        "        d2 = self.down1(d1)\n",
        "        d3 = self.down2(d2)\n",
        "        d4 = self.down3(d3)\n",
        "        d5 = self.down4(d4)\n",
        "        d6 = self.down5(d5)\n",
        "        d7 = self.down6(d6)\n",
        "        bottleneck = self.bottleneck(d7)\n",
        "        up1 = self.up1(bottleneck)\n",
        "        up2 = self.up2(torch.cat([up1, d7], 1))\n",
        "        up3 = self.up3(torch.cat([up2, d6], 1))\n",
        "        up4 = self.up4(torch.cat([up3, d5], 1))\n",
        "        up5 = self.up5(torch.cat([up4, d4], 1))\n",
        "        up6 = self.up6(torch.cat([up5, d3], 1))\n",
        "        up7 = self.up7(torch.cat([up6, d2], 1))\n",
        "        return self.final_up(torch.cat([up7, d1], 1))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator_noskip(nn.Module):\n",
        "    def __init__(self, in_channels=3, out_channels=3, features=64):\n",
        "        super().__init__()\n",
        "        self.initial_down = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, features, 4, 2, 1, padding_mode=\"reflect\"),\n",
        "            nn.LeakyReLU(0.2),\n",
        "        )\n",
        "        self.down1 = Block(features, features * 2, down=True, act=\"leaky\", use_dropout=False)\n",
        "        self.down2 = Block(\n",
        "            features * 2, features * 4, down=True, act=\"leaky\", use_dropout=False\n",
        "        )\n",
        "        self.down3 = Block(\n",
        "            features * 4, features * 8, down=True, act=\"leaky\", use_dropout=False\n",
        "        )\n",
        "        self.down4 = Block(\n",
        "            features * 8, features * 8, down=True, act=\"leaky\", use_dropout=False\n",
        "        )\n",
        "        self.down5 = Block(\n",
        "            features * 8, features * 8, down=True, act=\"leaky\", use_dropout=False\n",
        "        )\n",
        "        self.down6 = Block(\n",
        "            features * 8, features * 8, down=True, act=\"leaky\", use_dropout=False\n",
        "        )\n",
        "        self.bottleneck = nn.Sequential(\n",
        "            nn.Conv2d(features * 8, features * 8, 4, 2, 1), nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.up1 = Block(features * 8, features * 8, down=False, act=\"relu\", use_dropout=True)\n",
        "        self.up2 = Block(\n",
        "            features * 8, features * 8, down=False, act=\"relu\", use_dropout=True\n",
        "        )\n",
        "        self.up3 = Block(\n",
        "            features * 8, features * 8, down=False, act=\"relu\", use_dropout=True\n",
        "        )\n",
        "        self.up4 = Block(\n",
        "            features * 8, features * 8, down=False, act=\"relu\", use_dropout=False\n",
        "        )\n",
        "        self.up5 = Block(\n",
        "            features * 8, features * 4, down=False, act=\"relu\", use_dropout=False\n",
        "        )\n",
        "        self.up6 = Block(\n",
        "            features * 4, features * 2, down=False, act=\"relu\", use_dropout=False\n",
        "        )\n",
        "        self.up7 = Block(features * 2, features, down=False, act=\"relu\", use_dropout=False)\n",
        "        self.final_up = nn.Sequential(\n",
        "            nn.ConvTranspose2d(features, out_channels, kernel_size=4, stride=2, padding=1),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        d1 = self.initial_down(x)\n",
        "        d2 = self.down1(d1)\n",
        "        d3 = self.down2(d2)\n",
        "        d4 = self.down3(d3)\n",
        "        d5 = self.down4(d4)\n",
        "        d6 = self.down5(d5)\n",
        "        d7 = self.down6(d6)\n",
        "        bottleneck = self.bottleneck(d7)\n",
        "        up1 = self.up1(bottleneck)\n",
        "        up2 = self.up2(up1)\n",
        "        up3 = self.up3(up2)\n",
        "        up4 = self.up4(up3)\n",
        "        up5 = self.up5(up4)\n",
        "        up6 = self.up6(up5)\n",
        "        up7 = self.up7(up6)\n",
        "        return self.final_up(up7)"
      ],
      "metadata": {
        "id": "gl2x59eEcAO8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AYOItTosDYPO"
      },
      "outputs": [],
      "source": [
        "def test():\n",
        "    in_channels = 4\n",
        "    out_channels = 3\n",
        "    img_size = 256\n",
        "    x = torch.randn((2, in_channels, img_size, img_size))\n",
        "    gen = Generator(in_channels, out_channels)\n",
        "    #print(gen)\n",
        "    print(gen(x).shape)\n",
        "\n",
        "test()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmMq0L7fbhiH"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TrXtLU-8bkqM"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBYLhvZ_fc82"
      },
      "source": [
        "### Load images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BKP83t8yfdau"
      },
      "outputs": [],
      "source": [
        "class gen_dataset(Dataset):\n",
        "    def __init__(self, root_rgbd, root_real, transform=None, transform_rgbd=None):\n",
        "        self.root_rgbd = root_rgbd\n",
        "        self.root_real = root_real\n",
        "        self.transform = transform\n",
        "        self.transform_rgbd = transform_rgbd\n",
        "\n",
        "        # to make os.listdir not shuffle\n",
        "        #root_syntheic = os.getcwd()\n",
        "\n",
        "        self.rgbd_images = os.listdir(root_rgbd)\n",
        "        self.real_images = os.listdir(root_real)\n",
        "\n",
        "\n",
        "        self.length_dataset = max(len(self.rgbd_images), len(self.real_images))\n",
        "        self.rgbd_length = len(self.rgbd_images)\n",
        "        self.real_length = len(self.real_images)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length_dataset\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        rgbd_img = self.rgbd_images[index % self.rgbd_length]\n",
        "        real_img = self.real_images[index % self.real_length]\n",
        "\n",
        "        rgbd_path = os.path.join(self.root_rgbd, rgbd_img)\n",
        "        real_path = os.path.join(self.root_real, real_img)\n",
        "\n",
        "        #rgbd_img = np.array(Image.open(rgbd_path))\n",
        "        rgbd_img = np.array(Image.open(rgbd_path).convert(\"RGB\"))\n",
        "        real_img = np.array(Image.open(real_path).convert(\"RGB\"))\n",
        "        #real_img = real_img.permute(2,0,1)\n",
        "\n",
        "        if self.transform:\n",
        "\n",
        "            real_img = self.transform(image=real_img)[\"image\"]\n",
        "            rgbd_img = self.transform(image=rgbd_img)[\"image\"]\n",
        "        if self.transform_rgbd:\n",
        "            rgbd_img = self.transform_rgbd(image=rgbd_img)[\"image\"]\n",
        "\n",
        "        \n",
        "        return rgbd_img, real_img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvcrGciti-by"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFRt4b5li-8P"
      },
      "outputs": [],
      "source": [
        "def train_fn(disc_S, disc_R, gen_S, gen_R, loader, opt_disc, opt_gen, l1, G_loss_func, D_loss_func, d_scaler, g_scaler, epoch):\n",
        "    D_loss_all = 0\n",
        "    G_loss_all = 0\n",
        "    loop = tqdm(loader, leave=True)\n",
        "\n",
        "    for idx, (rgbd_img, real_img) in enumerate(loop):\n",
        "        #syntheic_img = syntheic_img.permute(0,3,1,2)\n",
        "        #depth_img = depth_img.permute(0,3,1,2)\n",
        "        #real_img = real_img.permute(0,3,1,2)\n",
        "\n",
        "        #input_img = syntheic_img\n",
        "        input_img = rgbd_img\n",
        "        #real_img = torch.cat([real_img, depth_img],1)\n",
        "        input_img = input_img.float()\n",
        "        real_img = real_img.float()\n",
        "        \n",
        "        input_img = input_img.to(DEVICE)\n",
        "        real_img = real_img.to(DEVICE)\n",
        "\n",
        "        \n",
        "        # Train Discriminators\n",
        "        with torch.cuda.amp.autocast():\n",
        "            # Disc R\n",
        "            fake_R = gen_R(input_img)\n",
        "            D_R_real = disc_R(real_img)\n",
        "            D_R_fake = disc_R(fake_R.detach())\n",
        "\n",
        "            #R_reals += D_R_real.mean().item()\n",
        "            #R_fakes += D_R_fake.mean().item()\n",
        "\n",
        "            D_R_real_loss = D_loss_func(D_R_real, torch.ones_like(D_R_real))\n",
        "            D_R_fake_loss = D_loss_func(D_R_fake, torch.zeros_like(D_R_fake))\n",
        "            D_R_loss = D_R_real_loss + D_R_fake_loss\n",
        "\n",
        "            # Disc S\n",
        "            fake_S = gen_S(real_img)\n",
        "            D_S_real = disc_S(input_img)\n",
        "            D_S_fake = disc_S(fake_S.detach())\n",
        "\n",
        "            D_S_real_loss = D_loss_func(D_S_real, torch.ones_like(D_S_real))\n",
        "            D_S_fake_loss = D_loss_func(D_S_fake, torch.zeros_like(D_S_fake))\n",
        "            D_S_loss = D_S_real_loss + D_S_fake_loss\n",
        "\n",
        "            # put it togethor\n",
        "            D_loss = (D_R_loss + D_S_loss)/2\n",
        "            D_loss_all += D_loss\n",
        "            #print('\\n'+str(D_loss.item()))\n",
        "\n",
        "        opt_disc.zero_grad()\n",
        "        d_scaler.scale(D_loss).backward()\n",
        "        d_scaler.step(opt_disc)\n",
        "        d_scaler.update()\n",
        "\n",
        "        # Train Generators\n",
        "        with torch.cuda.amp.autocast():\n",
        "            # adversarial loss for both generators\n",
        "            D_R_fake = disc_R(fake_R)\n",
        "            D_S_fake = disc_S(fake_S)\n",
        "            loss_G_R = G_loss_func(D_R_fake, torch.ones_like(D_R_fake))\n",
        "            loss_G_S = G_loss_func(D_S_fake, torch.ones_like(D_S_fake))\n",
        "\n",
        "            # cycle loss\n",
        "            cycle_S = gen_S(fake_R)\n",
        "            cycle_R = gen_R(fake_S)\n",
        "            cycle_S_loss = l1(input_img, cycle_S)\n",
        "            cycle_R_loss = l1(real_img, cycle_R)\n",
        "\n",
        "            # identity loss (set lambda_identity=0)\n",
        "            identity_S = 0 #gen_S(input_img)\n",
        "            identity_R = 0 #gen_R(real_img)\n",
        "            identity_S_loss = 0 #l1(input_img, identity_S)\n",
        "            identity_R_loss = 0 #l1(real_img, identity_R)\n",
        "\n",
        "            # add all togethor\n",
        "            G_loss = (\n",
        "                loss_G_S\n",
        "                + loss_G_R\n",
        "                + cycle_S_loss * LAMBDA_CYCLE\n",
        "                + cycle_R_loss * LAMBDA_CYCLE\n",
        "                + identity_R_loss * LAMBDA_IDENTITY\n",
        "                + identity_S_loss * LAMBDA_IDENTITY\n",
        "            )\n",
        "            \n",
        "            G_loss_all += G_loss\n",
        "            #print('\\n'+str(G_loss.item()))\n",
        "\n",
        "        opt_gen.zero_grad()\n",
        "        g_scaler.scale(G_loss).backward()\n",
        "        g_scaler.step(opt_gen)\n",
        "        g_scaler.update()\n",
        "\n",
        "        #fake_R = fake_R.squeeze()/2*255+.5*255\n",
        "        \n",
        "\n",
        "        if idx % 1000 == 0:\n",
        "            save_image(fake_R[0]*0.5+0.5, f\"/content/drive/MyDrive/Project/data/saved_images_rgb_pix/real_{epoch}_{idx}.png\")\n",
        "            #print(fake_R[0])\n",
        "            #save_image(fake_S[0], f\"/content/drive/MyDrive/Project/data/saved_images/syntheic_{idx}.png\")\n",
        "\n",
        "        #loop.set_postfix(R_real=R_reals/(idx+1), R_fake=R_fakes/(idx+1))\n",
        "        #loop.set_postfix(D_loss = D_loss.item(), G_loss = G_loss.item())\n",
        "\n",
        "        D_loss_avg = D_loss_all/(idx+1)\n",
        "        G_loss_avg = G_loss_all/(idx+1)\n",
        "\n",
        "        loop.set_postfix(D_loss = D_loss_avg.item(), G_loss = G_loss_avg.item(), epoch = epoch)\n",
        "\n",
        "    return D_loss_avg.item(), G_loss_avg.item() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "diAcLQBbjC9b"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "    disc_S = Discriminator(in_channels=3).to(DEVICE)\n",
        "    disc_R = Discriminator(in_channels=3).to(DEVICE)\n",
        "    gen_S = Generator(in_channels=3, out_channels=3).to(DEVICE)\n",
        "    gen_R = Generator(in_channels=3, out_channels=3).to(DEVICE)\n",
        "\n",
        "    opt_disc = optim.Adam(\n",
        "        list(disc_S.parameters())+list(disc_R.parameters()),\n",
        "        lr = LEARNING_RATE*2,\n",
        "        betas = (0.5, 0.999)\n",
        "    )\n",
        "    opt_gen = optim.Adam(\n",
        "        list(gen_S.parameters())+list(gen_R.parameters()),\n",
        "        lr = LEARNING_RATE*5,\n",
        "        betas = (0.5, 0.999)\n",
        "    )\n",
        "\n",
        "    #loss\n",
        "    L1 = nn.L1Loss()\n",
        "    mse = nn.MSELoss()\n",
        "    BCE = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    if LOAD_MODEL:\n",
        "        load_checkpoint(\n",
        "            CHECKPOINT_GEN_S, gen_S, opt_gen, LEARNING_RATE,\n",
        "        )\n",
        "\n",
        "        load_checkpoint(\n",
        "            CHECKPOINT_GEN_R, gen_R, opt_gen, LEARNING_RATE,\n",
        "        )\n",
        "\n",
        "        load_checkpoint(\n",
        "            CHECKPOINT_CRITIC_S, disc_S, opt_disc, LEARNING_RATE,\n",
        "        )\n",
        "\n",
        "        load_checkpoint(\n",
        "            CHECKPOINT_CRITIC_R, disc_R, opt_disc, LEARNING_RATE,\n",
        "        )\n",
        "\n",
        "\n",
        "    Dataset = gen_dataset(root_rgbd = \"/content/drive/MyDrive/Project/data/synthetic\",\n",
        "                      root_real = \"/content/drive/MyDrive/Project/data/real_resized_specfic\",\n",
        "                      transform=TRANSFORMS,\n",
        "                      transform_rgbd=None)\n",
        "\n",
        "    loader = DataLoader(Dataset, batch_size = BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory = True)\n",
        "\n",
        "    g_scaler = torch.cuda.amp.GradScaler()\n",
        "    d_scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "    D_loss_list = []\n",
        "    G_loss_list = []\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        D_loss_avg, G_loss_avg = train_fn(disc_S, disc_R, gen_S, gen_R, loader, opt_disc, opt_gen, L1, mse, mse, d_scaler, g_scaler, epoch)\n",
        "\n",
        "        D_loss_list.append(D_loss_avg)\n",
        "        G_loss_list.append(G_loss_avg)\n",
        "        \n",
        "        if SAVE_MODEL:\n",
        "            save_checkpoint(gen_S, opt_gen, PATH=CHECKPOINT_GEN_S)\n",
        "            save_checkpoint(gen_R, opt_gen, PATH=CHECKPOINT_GEN_R)\n",
        "            save_checkpoint(disc_S, opt_disc, PATH=CHECKPOINT_CRITIC_S)\n",
        "            save_checkpoint(disc_R, opt_disc, PATH=CHECKPOINT_CRITIC_R)\n",
        "\n",
        "    print(D_loss_list)\n",
        "    print(G_loss_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pTO7KLLdjS5v"
      },
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpkirUAhxDhO"
      },
      "source": [
        "## Clean memory\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vNxLE0kTTRXP"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "53Sq3-4dYsGO"
      },
      "outputs": [],
      "source": [
        "torch.cuda.max_memory_reserved()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EbDqMrOtbgWY"
      },
      "outputs": [],
      "source": [
        "!cat /proc/meminfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Im__gZ-NcIjY"
      },
      "outputs": [],
      "source": [
        "!pip install GPUtil\n",
        "\n",
        "from GPUtil import showUtilization as gpu_usage\n",
        "from numba import cuda\n",
        "\n",
        "def free_gpu_cache():\n",
        "    print(\"Initial GPU Usage\")\n",
        "    gpu_usage()                             \n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    cuda.select_device(0)\n",
        "    cuda.close()\n",
        "    cuda.select_device(0)\n",
        "\n",
        "    print(\"GPU Usage after emptying the cache\")\n",
        "    gpu_usage()\n",
        "\n",
        "free_gpu_cache()  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzUNi6RfbhDU"
      },
      "source": [
        "prob withwith cyclegan:https://zhuanlan.zhihu.com/p/45164258"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imVzZ_WmqnaF"
      },
      "source": [
        "## Test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SabwExdNqo6-"
      },
      "outputs": [],
      "source": [
        "class gen_dataset_test(Dataset):\n",
        "    def __init__(self, root_rgbd, root_real, root_compare_rgb, root_compare_depth, transform=None, transform_rgbd=None):\n",
        "        self.root_rgbd = root_rgbd\n",
        "        self.root_real = root_real\n",
        "        self.root_compare_rgb = root_compare_rgb\n",
        "        self.root_compare_depth = root_compare_depth\n",
        "        self.transform = transform\n",
        "        self.transform_rgbd = transform_rgbd\n",
        "\n",
        "        # to make os.listdir not shuffle\n",
        "        #root_syntheic = os.getcwd()\n",
        "\n",
        "        self.rgbd_images = os.listdir(root_rgbd)\n",
        "        self.real_images = os.listdir(root_real)\n",
        "\n",
        "\n",
        "        self.length_dataset = max(len(self.rgbd_images), len(self.real_images))\n",
        "        self.rgbd_length = len(self.rgbd_images)\n",
        "        self.real_length = len(self.real_images)\n",
        "\n",
        "        #self.rgbd_images.sort()\n",
        "        self.compare_rgb_images = os.listdir(root_compare_rgb)\n",
        "        self.compare_rgb_images.sort()\n",
        "        self.compare_depth_images = os.listdir(root_compare_depth)\n",
        "        self.compare_depth_images.sort()        \n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length_dataset\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        rgbd_img = self.rgbd_images[index % self.rgbd_length]\n",
        "        real_img = self.real_images[index % self.real_length]\n",
        "        compare_rgb_img = self.compare_rgb_images[index % self.real_length]\n",
        "        compare_depth_img = self.compare_depth_images[index % self.real_length]\n",
        "\n",
        "        rgbd_path = os.path.join(self.root_rgbd, rgbd_img)\n",
        "        real_path = os.path.join(self.root_real, real_img)\n",
        "        compare_rgb_path = os.path.join(self.root_compare_rgb, compare_rgb_img)\n",
        "        compare_depth_path = os.path.join(self.root_compare_depth, compare_depth_img)\n",
        "\n",
        "        rgbd_img = np.array(Image.open(rgbd_path).convert(\"RGB\"))\n",
        "        real_img = np.array(Image.open(real_path).convert(\"RGB\"))\n",
        "\n",
        "\n",
        "        if self.transform:\n",
        "            real_img = self.transform(image=real_img)[\"image\"]\n",
        "            rgbd_img = self.transform(image=rgbd_img)[\"image\"]\n",
        "\n",
        "        \n",
        "        return rgbd_img, real_img, compare_rgb_path, compare_depth_path, rgbd_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cFvGZp7Aqsfm"
      },
      "outputs": [],
      "source": [
        "def test_fn(disc_S, disc_R, gen_S, gen_R, loader, opt_disc, opt_gen, epoch):\n",
        "    D_loss_all = 0\n",
        "    G_loss_all = 0\n",
        "    loop = tqdm(loader, leave=True)\n",
        "\n",
        "    for idx, (rgbd_img, real_img, compare_rgb_path, compare_depth_path, rgbd_path) in enumerate(loop):\n",
        "        input_img = rgbd_img\n",
        "\n",
        "        input_img = input_img.float()\n",
        "        real_img = real_img.float()\n",
        "        \n",
        "        input_img = input_img.to(DEVICE)\n",
        "        real_img = real_img.to(DEVICE)\n",
        "\n",
        "        fake_R = gen_R(input_img)\n",
        "\n",
        "        if idx % 10 == 0:\n",
        "            save_image(fake_R[0]*0.5+0.5, f\"/content/drive/MyDrive/Project/data/result_rgb_pix/output/output_{epoch}_{idx}.png\")\n",
        "\n",
        "            rgb_img = cv2.imread((compare_rgb_path[0]), cv2.IMREAD_COLOR)\n",
        "            #depth_img = cv2.imread((compare_depth_path[0]), cv2.IMREAD_GRAYSCALE)\n",
        "            cv2.imwrite(f\"/content/drive/MyDrive/Project/data/result_rgb_pix/synthetic/input_rgb_{epoch}_{idx}.png\", rgb_img)\n",
        "            #cv2.imwrite(f\"/content/drive/MyDrive/Project/data/result_rgb_doubleunet/depth/input_depth_{epoch}_{idx}.png\", depth_img) \n",
        "\n",
        "            #print(fake_R[0])\n",
        "            #out_image = input_img[:,0:3,:,:]\n",
        "            #save_image(out_image[0], f\"/content/drive/MyDrive/Project/data/saved_images_rgbd_pix/input_{epoch}_{idx}.png\")\n",
        "\n",
        "        #loop.set_postfix(R_real=R_reals/(idx+1), R_fake=R_fakes/(idx+1))\n",
        "        #loop.set_postfix(D_loss = D_loss.item(), G_loss = G_loss.item())\n",
        "\n",
        "        D_loss_avg = D_loss_all/(idx+1)\n",
        "        G_loss_avg = G_loss_all/(idx+1)\n",
        "\n",
        "        loop.set_postfix(epoch = epoch)\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A9L1MZ61quR6"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "    disc_S = Discriminator(in_channels=3).to(DEVICE)\n",
        "    disc_R = Discriminator(in_channels=3).to(DEVICE)\n",
        "    gen_S = Generator(in_channels=3, out_channels=3).to(DEVICE)\n",
        "    gen_R = Generator(in_channels=3, out_channels=3).to(DEVICE)\n",
        "\n",
        "    opt_disc = optim.Adam(\n",
        "        list(disc_S.parameters())+list(disc_R.parameters()),\n",
        "        lr = LEARNING_RATE,\n",
        "        betas = (0.5, 0.999)\n",
        "    )\n",
        "    opt_gen = optim.Adam(\n",
        "        list(gen_S.parameters())+list(gen_R.parameters()),\n",
        "        lr = LEARNING_RATE,\n",
        "        betas = (0.5, 0.999)\n",
        "    )\n",
        "\n",
        "    #loss\n",
        "    L1 = nn.L1Loss()\n",
        "    mse = nn.MSELoss()\n",
        "\n",
        "    LOAD_MODEL = True\n",
        "\n",
        "    if LOAD_MODEL:\n",
        "        load_checkpoint(\n",
        "            CHECKPOINT_GEN_S, gen_S, opt_gen, LEARNING_RATE,\n",
        "        )\n",
        "\n",
        "        load_checkpoint(\n",
        "            CHECKPOINT_GEN_R, gen_R, opt_gen, LEARNING_RATE,\n",
        "        )\n",
        "\n",
        "        load_checkpoint(\n",
        "            CHECKPOINT_CRITIC_S, disc_S, opt_disc, LEARNING_RATE,\n",
        "        )\n",
        "\n",
        "        load_checkpoint(\n",
        "            CHECKPOINT_CRITIC_R, disc_R, opt_disc, LEARNING_RATE,\n",
        "        )\n",
        "\n",
        "\n",
        "    Dataset = gen_dataset_test(root_rgbd = \"/content/drive/MyDrive/Project/data/synthetic\",\n",
        "                      root_real = \"/content/drive/MyDrive/Project/data/real_resized\",\n",
        "                      root_compare_rgb = \"/content/drive/MyDrive/Project/data/synthetic\",\n",
        "                      root_compare_depth = \"/content/drive/MyDrive/Project/data/depth map\",\n",
        "                      transform=TRANSFORMS,\n",
        "                      transform_rgbd=TRANSFORMS_rgbd)\n",
        "\n",
        "    loader = DataLoader(Dataset, batch_size = BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory = True)\n",
        "\n",
        "\n",
        "    D_loss_list = []\n",
        "    G_loss_list = []\n",
        "\n",
        "    NUM_EPOCHS = 1\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        test_fn(disc_S, disc_R, gen_S, gen_R, loader, opt_disc, opt_gen, epoch)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "llFaFMAoqv1s"
      },
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kswtUGESq2D3"
      },
      "source": [
        "## Metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WH01zUh8q3oG"
      },
      "outputs": [],
      "source": [
        "pip install pytorch-fid==0.1.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EkBI8_a7q6vW"
      },
      "outputs": [],
      "source": [
        "import pytorch_fid.fid_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-p-oNsQGq8hB"
      },
      "outputs": [],
      "source": [
        "pytorch_fid.fid_score.calculate_fid_given_paths(['/content/drive/MyDrive/Project/data/real_resized_specfic', '/content/drive/MyDrive/Project/data/result_rgb_pix/output'], 1, 'cude', 2048)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S4LWTAYZtB8b"
      },
      "outputs": [],
      "source": [
        "pytorch_fid.fid_score.calculate_fid_given_paths(['/content/drive/MyDrive/Project/data/real_resized_specfic', '/content/drive/MyDrive/Project/data/result_rgb_original/output'], 1, 'cude', 2048)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "2qUJujsXbO3h",
        "zmAlIU2abU_9"
      ],
      "provenance": [],
      "mount_file_id": "1ZQGjYqmzw2KaTkH1wk-0Fs9dcpN-0vN6",
      "authorship_tag": "ABX9TyM+YAIA6zeWUkYQlgtU6AHJ"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}